# Contributing to Synesthesia

ğŸ¶ Thank you for your interest in contributing to Synesthesia â€” an open-source AI music video generation pipeline.

We welcome contributions from developers, artists, and creatives alike. Hereâ€™s how you can help:

---

## ğŸ› ï¸ Getting Started

1. **Fork the Repository**
2. **Clone Your Fork**
   ```bash
   git clone https://github.com/YOUR_USERNAME/synesthesia.git
   cd synesthesia
   ```
3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“ Structure Overview

- `audio_processor.py` â€” Transcribes lyrics and detects instrumental gaps
- `prompt_generator.py` â€” Generates scene prompts from lyrics and mood
- `generate_video.py` â€” Controls text-to-video generation
- `video_assembler.py` â€” Compiles the final video with transitions and audio
- `lambda_control.py` â€” Launch/terminate GPU instances on Lambda Cloud
- `config/config.json` â€” Controls video/audio/model settings

---

## ğŸ§ª How to Contribute

- ğŸ”§ **Bug Fixes** â€” See [Issues](../../issues) and submit a PR with a clear description.
- ğŸ§  **Feature Suggestions** â€” Open an issue or submit a draft pull request.
- ğŸ§ª **Testing** â€” Add tests for `prompt_generator` or `video_assembler`.
- ğŸ§° **Refactors** â€” Make the code more readable or modular.

---

## ğŸ§¼ Code Standards

- Follow [PEP8](https://pep8.org/)
- Include docstrings for functions and classes
- Use descriptive commit messages
- Pull requests should target the `main` branch

---

## ğŸ“„ Licensing

All contributions will be licensed under the [MIT License](LICENSE).

---

Thank you for helping us bring music to life visually, one verse at a time.

â€” The Synesthesia Team ğŸ¨ğŸ¶
